{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = [i for i in range(11)]\n",
    "x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "x_train = np.array(x_values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important: 2D is Required\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 2x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19., 21.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear model\n",
    " - True equation: y = 2x + 1\n",
    "2. Forward\n",
    " - Example:\n",
    "        - Input x = 1\n",
    "        - Output $\\hat{y}$ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate model class\n",
    "    - Input: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n",
    "    - Desired Output: [ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19., 21.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 151.26153564453125\n",
      "Epoch: 1, loss: 12.543886184692383\n",
      "Epoch: 2, loss: 1.2268285751342773\n",
      "Epoch: 3, loss: 0.30145785212516785\n",
      "Epoch: 4, loss: 0.2237296998500824\n",
      "Epoch: 5, loss: 0.21516607701778412\n",
      "Epoch: 6, loss: 0.2122683823108673\n",
      "Epoch: 7, loss: 0.20985785126686096\n",
      "Epoch: 8, loss: 0.2075110524892807\n",
      "Epoch: 9, loss: 0.205193430185318\n",
      "Epoch: 10, loss: 0.20290207862854004\n",
      "Epoch: 11, loss: 0.20063625276088715\n",
      "Epoch: 12, loss: 0.19839586317539215\n",
      "Epoch: 13, loss: 0.19618040323257446\n",
      "Epoch: 14, loss: 0.19398970901966095\n",
      "Epoch: 15, loss: 0.19182337820529938\n",
      "Epoch: 16, loss: 0.1896812468767166\n",
      "Epoch: 17, loss: 0.1875631958246231\n",
      "Epoch: 18, loss: 0.18546876311302185\n",
      "Epoch: 19, loss: 0.18339751660823822\n",
      "Epoch: 20, loss: 0.18134963512420654\n",
      "Epoch: 21, loss: 0.17932458221912384\n",
      "Epoch: 22, loss: 0.1773221343755722\n",
      "Epoch: 23, loss: 0.1753418892621994\n",
      "Epoch: 24, loss: 0.1733839511871338\n",
      "Epoch: 25, loss: 0.17144781351089478\n",
      "Epoch: 26, loss: 0.16953322291374207\n",
      "Epoch: 27, loss: 0.1676400750875473\n",
      "Epoch: 28, loss: 0.1657681167125702\n",
      "Epoch: 29, loss: 0.1639169156551361\n",
      "Epoch: 30, loss: 0.16208642721176147\n",
      "Epoch: 31, loss: 0.1602766066789627\n",
      "Epoch: 32, loss: 0.15848678350448608\n",
      "Epoch: 33, loss: 0.15671691298484802\n",
      "Epoch: 34, loss: 0.15496692061424255\n",
      "Epoch: 35, loss: 0.15323632955551147\n",
      "Epoch: 36, loss: 0.15152522921562195\n",
      "Epoch: 37, loss: 0.14983323216438293\n",
      "Epoch: 38, loss: 0.14816007018089294\n",
      "Epoch: 39, loss: 0.14650551974773407\n",
      "Epoch: 40, loss: 0.1448695808649063\n",
      "Epoch: 41, loss: 0.14325179159641266\n",
      "Epoch: 42, loss: 0.14165210723876953\n",
      "Epoch: 43, loss: 0.14007039368152618\n",
      "Epoch: 44, loss: 0.13850612938404083\n",
      "Epoch: 45, loss: 0.13695953786373138\n",
      "Epoch: 46, loss: 0.13543011248111725\n",
      "Epoch: 47, loss: 0.13391776382923126\n",
      "Epoch: 48, loss: 0.1324222981929779\n",
      "Epoch: 49, loss: 0.13094358146190643\n",
      "Epoch: 50, loss: 0.12948136031627655\n",
      "Epoch: 51, loss: 0.12803547084331512\n",
      "Epoch: 52, loss: 0.12660567462444305\n",
      "Epoch: 53, loss: 0.12519191205501556\n",
      "Epoch: 54, loss: 0.12379391491413116\n",
      "Epoch: 55, loss: 0.1224115788936615\n",
      "Epoch: 56, loss: 0.12104467302560806\n",
      "Epoch: 57, loss: 0.11969294399023056\n",
      "Epoch: 58, loss: 0.11835635453462601\n",
      "Epoch: 59, loss: 0.11703462153673172\n",
      "Epoch: 60, loss: 0.11572765558958054\n",
      "Epoch: 61, loss: 0.11443544179201126\n",
      "Epoch: 62, loss: 0.11315753310918808\n",
      "Epoch: 63, loss: 0.1118939220905304\n",
      "Epoch: 64, loss: 0.11064441502094269\n",
      "Epoch: 65, loss: 0.10940895229578018\n",
      "Epoch: 66, loss: 0.10818710178136826\n",
      "Epoch: 67, loss: 0.10697903484106064\n",
      "Epoch: 68, loss: 0.10578438639640808\n",
      "Epoch: 69, loss: 0.10460305213928223\n",
      "Epoch: 70, loss: 0.1034349724650383\n",
      "Epoch: 71, loss: 0.10227994620800018\n",
      "Epoch: 72, loss: 0.10113780200481415\n",
      "Epoch: 73, loss: 0.10000841319561005\n",
      "Epoch: 74, loss: 0.0988917127251625\n",
      "Epoch: 75, loss: 0.09778738021850586\n",
      "Epoch: 76, loss: 0.09669539332389832\n",
      "Epoch: 77, loss: 0.0956156849861145\n",
      "Epoch: 78, loss: 0.09454784542322159\n",
      "Epoch: 79, loss: 0.09349207580089569\n",
      "Epoch: 80, loss: 0.09244806319475174\n",
      "Epoch: 81, loss: 0.09141567349433899\n",
      "Epoch: 82, loss: 0.09039481729269028\n",
      "Epoch: 83, loss: 0.08938542753458023\n",
      "Epoch: 84, loss: 0.08838734775781631\n",
      "Epoch: 85, loss: 0.08740027993917465\n",
      "Epoch: 86, loss: 0.08642430603504181\n",
      "Epoch: 87, loss: 0.08545919507741928\n",
      "Epoch: 88, loss: 0.08450490236282349\n",
      "Epoch: 89, loss: 0.0835612490773201\n",
      "Epoch: 90, loss: 0.08262811601161957\n",
      "Epoch: 91, loss: 0.0817054733633995\n",
      "Epoch: 92, loss: 0.08079302310943604\n",
      "Epoch: 93, loss: 0.07989088445901871\n",
      "Epoch: 94, loss: 0.07899869233369827\n",
      "Epoch: 95, loss: 0.07811655849218369\n",
      "Epoch: 96, loss: 0.07724426686763763\n",
      "Epoch: 97, loss: 0.0763816386461258\n",
      "Epoch: 98, loss: 0.07552871108055115\n",
      "Epoch: 99, loss: 0.07468530535697937\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epochs += 1\n",
    "    \n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    # Clear gradients w.r.t parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward to get outputs\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Getting gradients w.r.t parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Upadting parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: {}, loss: {}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49163243],\n",
       "       [ 2.564842  ],\n",
       "       [ 4.6380515 ],\n",
       "       [ 6.711261  ],\n",
       "       [ 8.784471  ],\n",
       "       [10.85768   ],\n",
       "       [12.930889  ],\n",
       "       [15.004099  ],\n",
       "       [17.077309  ],\n",
       "       [19.150518  ],\n",
       "       [21.223728  ]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [15.],\n",
       "       [17.],\n",
       "       [19.],\n",
       "       [21.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = 2x + 1\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear figure\n",
    "plt.clf()\n",
    "\n",
    "# Get Predictions\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "\n",
    "# Plot true data\n",
    "plt.plot(x_train, y_train, 'go', label=\"True data\", alpha=0.5)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(x_train, predicted, '--', label=\"Predictions\", alpha=0.5)\n",
    "\n",
    "# Legend and plots\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "\n",
    "if save_model is True:\n",
    "    # Saves\n",
    "    # Alpha & Beta\n",
    "    torch.save(model.state_dict(), 'awesome_model.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model\n",
    "load_model = False\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('awesome_model.pk1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Linear Regression model with PyTorch (GPU)\n",
    "\n",
    "CPU Summary = The proccess from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GPU: 2 Things must be on the GPU **\n",
    "- Model\n",
    "- Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 67.61626434326172\n",
      "Epoch: 1, loss: 5.5734148025512695\n",
      "Epoch: 2, loss: 0.5121253132820129\n",
      "Epoch: 3, loss: 0.09865007549524307\n",
      "Epoch: 4, loss: 0.06428910791873932\n",
      "Epoch: 5, loss: 0.06085832789540291\n",
      "Epoch: 6, loss: 0.059957485646009445\n",
      "Epoch: 7, loss: 0.059269871562719345\n",
      "Epoch: 8, loss: 0.05860653892159462\n",
      "Epoch: 9, loss: 0.05795199051499367\n",
      "Epoch: 10, loss: 0.05730482190847397\n",
      "Epoch: 11, loss: 0.05666492506861687\n",
      "Epoch: 12, loss: 0.05603215470910072\n",
      "Epoch: 13, loss: 0.05540647357702255\n",
      "Epoch: 14, loss: 0.054787732660770416\n",
      "Epoch: 15, loss: 0.054175931960344315\n",
      "Epoch: 16, loss: 0.05357092618942261\n",
      "Epoch: 17, loss: 0.052972689270973206\n",
      "Epoch: 18, loss: 0.05238116905093193\n",
      "Epoch: 19, loss: 0.05179627239704132\n",
      "Epoch: 20, loss: 0.05121784657239914\n",
      "Epoch: 21, loss: 0.05064592510461807\n",
      "Epoch: 22, loss: 0.05008035525679588\n",
      "Epoch: 23, loss: 0.04952109232544899\n",
      "Epoch: 24, loss: 0.04896808788180351\n",
      "Epoch: 25, loss: 0.04842129722237587\n",
      "Epoch: 26, loss: 0.04788055270910263\n",
      "Epoch: 27, loss: 0.04734591394662857\n",
      "Epoch: 28, loss: 0.046817176043987274\n",
      "Epoch: 29, loss: 0.046294376254081726\n",
      "Epoch: 30, loss: 0.04577745869755745\n",
      "Epoch: 31, loss: 0.04526621103286743\n",
      "Epoch: 32, loss: 0.044760748744010925\n",
      "Epoch: 33, loss: 0.04426093026995659\n",
      "Epoch: 34, loss: 0.04376669600605965\n",
      "Epoch: 35, loss: 0.04327792674303055\n",
      "Epoch: 36, loss: 0.042794667184352875\n",
      "Epoch: 37, loss: 0.04231679439544678\n",
      "Epoch: 38, loss: 0.041844192892313004\n",
      "Epoch: 39, loss: 0.0413769856095314\n",
      "Epoch: 40, loss: 0.040914908051490784\n",
      "Epoch: 41, loss: 0.04045802354812622\n",
      "Epoch: 42, loss: 0.040006257593631744\n",
      "Epoch: 43, loss: 0.03955952078104019\n",
      "Epoch: 44, loss: 0.039117708802223206\n",
      "Epoch: 45, loss: 0.038680922240018845\n",
      "Epoch: 46, loss: 0.03824899345636368\n",
      "Epoch: 47, loss: 0.03782183304429054\n",
      "Epoch: 48, loss: 0.037399474531412125\n",
      "Epoch: 49, loss: 0.03698185831308365\n",
      "Epoch: 50, loss: 0.03656890615820885\n",
      "Epoch: 51, loss: 0.03616051748394966\n",
      "Epoch: 52, loss: 0.03575674444437027\n",
      "Epoch: 53, loss: 0.03535746783018112\n",
      "Epoch: 54, loss: 0.03496260941028595\n",
      "Epoch: 55, loss: 0.034572191536426544\n",
      "Epoch: 56, loss: 0.034186117351055145\n",
      "Epoch: 57, loss: 0.03380437567830086\n",
      "Epoch: 58, loss: 0.033426884561777115\n",
      "Epoch: 59, loss: 0.03305359557271004\n",
      "Epoch: 60, loss: 0.032684508711099625\n",
      "Epoch: 61, loss: 0.032319508492946625\n",
      "Epoch: 62, loss: 0.03195856139063835\n",
      "Epoch: 63, loss: 0.031601693481206894\n",
      "Epoch: 64, loss: 0.031248819082975388\n",
      "Epoch: 65, loss: 0.030899925157427788\n",
      "Epoch: 66, loss: 0.030554814264178276\n",
      "Epoch: 67, loss: 0.030213613063097\n",
      "Epoch: 68, loss: 0.02987624704837799\n",
      "Epoch: 69, loss: 0.029542623087763786\n",
      "Epoch: 70, loss: 0.0292127076536417\n",
      "Epoch: 71, loss: 0.028886502608656883\n",
      "Epoch: 72, loss: 0.028563957661390305\n",
      "Epoch: 73, loss: 0.028244949877262115\n",
      "Epoch: 74, loss: 0.02792954444885254\n",
      "Epoch: 75, loss: 0.027617692947387695\n",
      "Epoch: 76, loss: 0.027309244498610497\n",
      "Epoch: 77, loss: 0.027004340663552284\n",
      "Epoch: 78, loss: 0.0267027635127306\n",
      "Epoch: 79, loss: 0.02640453353524208\n",
      "Epoch: 80, loss: 0.026109682396054268\n",
      "Epoch: 81, loss: 0.02581816352903843\n",
      "Epoch: 82, loss: 0.025529811158776283\n",
      "Epoch: 83, loss: 0.025244735181331635\n",
      "Epoch: 84, loss: 0.024962805211544037\n",
      "Epoch: 85, loss: 0.024684108793735504\n",
      "Epoch: 86, loss: 0.024408431723713875\n",
      "Epoch: 87, loss: 0.024135848507285118\n",
      "Epoch: 88, loss: 0.023866398259997368\n",
      "Epoch: 89, loss: 0.023599835112690926\n",
      "Epoch: 90, loss: 0.023336302489042282\n",
      "Epoch: 91, loss: 0.023075738921761513\n",
      "Epoch: 92, loss: 0.02281799353659153\n",
      "Epoch: 93, loss: 0.022563202306628227\n",
      "Epoch: 94, loss: 0.022311225533485413\n",
      "Epoch: 95, loss: 0.022062094882130623\n",
      "Epoch: 96, loss: 0.021815743297338486\n",
      "Epoch: 97, loss: 0.02157214842736721\n",
      "Epoch: 98, loss: 0.021331222727894783\n",
      "Epoch: 99, loss: 0.021093031391501427\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Same\n",
    "##\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "    input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "\n",
    "##\n",
    "## GPU\n",
    "##\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "##\n",
    "## Same\n",
    "##\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epochs += 1\n",
    "    \n",
    "    ##\n",
    "    ## GPU\n",
    "    ##\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    ##\n",
    "    ## Same\n",
    "    ##\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: {}, loss: {}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
